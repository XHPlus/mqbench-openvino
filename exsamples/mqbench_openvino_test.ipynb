{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba064a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from mqbench.convert_deploy import convert_deploy\n",
    "from mqbench.prepare_by_platform import prepare_by_platform, BackendType\n",
    "from mqbench.utils.state import enable_calibration, enable_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4877ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mqbench\n",
    "from mqbench.convert_deploy import convert_deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34166392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920499a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NetBN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(NetBN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 40, 3, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(40)\n",
    "        self.conv2 = nn.Conv2d(40, 40, 3, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(40, 40, 3, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.fc = nn.Linear(40, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        x = x.mean(dim=[2,3])\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6c1a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    lossLayer = torch.nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = lossLayer(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()\n",
    "            ))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += lossLayer(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(\n",
    "        test_loss, 100. * correct / len(test_loader.dataset)\n",
    "    ))\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "test_batch_size = 256\n",
    "seed = 1\n",
    "epochs = 15\n",
    "lr = 0.003\n",
    "save_model = True\n",
    "using_bn = True\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                        transforms.RandomCrop(32, padding=4),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])),\n",
    "    batch_size=test_batch_size, shuffle=False, num_workers=1, pin_memory=True\n",
    ")\n",
    "\n",
    "if using_bn:\n",
    "    model = NetBN(num_channels=3).to(device)\n",
    "else:\n",
    "    model = Net(num_channels=3).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "if save_model:\n",
    "    os.makedirs('ckpt',exist_ok = True)\n",
    "    if using_bn:\n",
    "        torch.save(model.state_dict(), 'ckpt/mnist_cnnbn.pt')\n",
    "    else:\n",
    "        torch.save(model.state_dict(), 'ckpt/mnist_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0d1bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.OPENVINO Mode: Training\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: LearnableFakeQuantize Params: {}\n",
      "    Oberver:      MinMaxObserver Params: Symmetric: True / Bitwidth: 8 / Per channel: True / Pot scale: False\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: LearnableFakeQuantize Params: {}\n",
      "    Oberver:      EMAMinMaxObserver Params: Symmetric: True / Bitwidth: 8 / Per channel: False / Pot scale: False\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Now all weight quantizers will effectively use only 7 bits out of 8 bits. This resolves the overflow issue problem on AVX2 and AVX-512 machines.\n",
      "[MQBENCH] INFO: Insert act quant x_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set conv1 post act quantize to 8 bit unsigned type.\n",
      "[MQBENCH] INFO: Insert act quant conv1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set conv2 post act quantize to 8 bit unsigned type.\n",
      "[MQBENCH] INFO: Insert act quant conv2_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set conv3 post act quantize to 8 bit unsigned type.\n",
      "[MQBENCH] INFO: Insert act quant conv3_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Set mean_1 post act quantize to 8 bit unsigned type.\n",
      "[MQBENCH] INFO: Insert act quant mean_1_post_act_fake_quantizer\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n"
     ]
    }
   ],
   "source": [
    "model = model.cpu().train()\n",
    "\n",
    "if save_model:\n",
    "    if using_bn:\n",
    "        model.load_state_dict(torch.load('ckpt/mnist_cnnbn.pt', map_location='cpu'))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load('ckpt/mnist_cnn.pt', map_location='cpu'))\n",
    "    \n",
    "model_mqbench = prepare_by_platform(model, BackendType.OPENVINO)\n",
    "model_mqbench = model_mqbench.to(device)\n",
    "# before training, we recommend to enable observers for calibration in several batches, and then enable quantization.\n",
    "enable_calibration(model_mqbench)\n",
    "model_mqbench = model_mqbench.to(device)\n",
    "model_mqbench.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        # do forward procedures\n",
    "        data = data.to(device)\n",
    "        model_mqbench(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1845d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7246, Accuracy: 75%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model_mqbench, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b01a8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n",
      "Train Epoch: 1 [0/50000]\tLoss: 0.956195\n",
      "Train Epoch: 1 [12800/50000]\tLoss: 0.753290\n",
      "Train Epoch: 1 [25600/50000]\tLoss: 0.719596\n",
      "Train Epoch: 1 [38400/50000]\tLoss: 0.769043\n",
      "\n",
      "Test set: Average loss: 0.6960, Accuracy: 76%\n",
      "\n",
      "Train Epoch: 2 [0/50000]\tLoss: 0.625557\n",
      "Train Epoch: 2 [12800/50000]\tLoss: 0.648791\n",
      "Train Epoch: 2 [25600/50000]\tLoss: 0.678966\n",
      "Train Epoch: 2 [38400/50000]\tLoss: 0.708362\n",
      "\n",
      "Test set: Average loss: 0.7010, Accuracy: 76%\n",
      "\n",
      "Train Epoch: 3 [0/50000]\tLoss: 0.683164\n",
      "Train Epoch: 3 [12800/50000]\tLoss: 0.770475\n",
      "Train Epoch: 3 [25600/50000]\tLoss: 0.796394\n",
      "Train Epoch: 3 [38400/50000]\tLoss: 0.800356\n",
      "\n",
      "Test set: Average loss: 0.6729, Accuracy: 77%\n",
      "\n",
      "Train Epoch: 4 [0/50000]\tLoss: 0.646614\n",
      "Train Epoch: 4 [12800/50000]\tLoss: 0.622016\n",
      "Train Epoch: 4 [25600/50000]\tLoss: 0.771547\n",
      "Train Epoch: 4 [38400/50000]\tLoss: 0.644924\n",
      "\n",
      "Test set: Average loss: 0.6832, Accuracy: 77%\n",
      "\n",
      "Train Epoch: 5 [0/50000]\tLoss: 0.777149\n",
      "Train Epoch: 5 [12800/50000]\tLoss: 0.701128\n",
      "Train Epoch: 5 [25600/50000]\tLoss: 0.797683\n",
      "Train Epoch: 5 [38400/50000]\tLoss: 0.740046\n",
      "\n",
      "Test set: Average loss: 0.7109, Accuracy: 76%\n",
      "\n",
      "Train Epoch: 6 [0/50000]\tLoss: 0.606946\n",
      "Train Epoch: 6 [12800/50000]\tLoss: 0.724596\n",
      "Train Epoch: 6 [25600/50000]\tLoss: 0.596705\n",
      "Train Epoch: 6 [38400/50000]\tLoss: 0.659280\n",
      "\n",
      "Test set: Average loss: 0.6863, Accuracy: 77%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_mqbench.zero_grad()\n",
    "model_mqbench.train()\n",
    "enable_quantization(model_mqbench)\n",
    "\n",
    "optimizer = optim.AdamW(model_mqbench.parameters(), lr=lr*0.5)\n",
    "epochs = 6\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model_mqbench, device, train_loader, optimizer, epoch)\n",
    "    test(model_mqbench, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fdc8a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Merge BN for deploy.\n",
      "[MQBENCH] INFO: Export to onnx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbtian/MQBench0130/mqbench/fake_quantize/lsq.py:62: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.observer_enabled[0] == 1:\n",
      "/home/hbtian/MQBench0130/mqbench/fake_quantize/lsq.py:76: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  self.scale.data.clamp_(min=self.eps.item())\n",
      "/home/hbtian/MQBench0130/mqbench/fake_quantize/lsq.py:78: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.fake_quant_enabled[0] == 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Extract qparams for OPENVINO.\n",
      "[MQBENCH] INFO: Finish deploy process.\n"
     ]
    }
   ],
   "source": [
    "input_shape={'data': [1, 3, 32, 32]}\n",
    "convert_deploy(model_mqbench.eval(), BackendType.OPENVINO, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728c3af",
   "metadata": {},
   "source": [
    "# test openvino inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6cc8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: openvino-dev in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (2021.4.2)\n",
      "Requirement already satisfied: fast-ctc-decode>=0.2.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.3.0)\n",
      "Requirement already satisfied: editdistance>=0.5.3 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.6.0)\n",
      "Requirement already satisfied: rawpy>=0.16.0 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.17.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (2.27.0)\n",
      "Requirement already satisfied: addict>=2.4.0 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (4.62.3)\n",
      "Requirement already satisfied: pydicom>=2.1.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (2.2.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.7.1)\n",
      "Requirement already satisfied: py-cpuinfo>=7.0.0 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (8.0.0)\n",
      "Requirement already satisfied: pillow>=8.1.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (8.4.0)\n",
      "Requirement already satisfied: openvino==2021.4.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (2021.4.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.0.2)\n",
      "Requirement already satisfied: scipy~=1.5.4 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.5.4)\n",
      "Requirement already satisfied: opencv-python==4.5.* in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (4.5.5.62)\n",
      "Requirement already satisfied: shapely>=1.7.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.8.0)\n",
      "Requirement already satisfied: hyperopt~=0.1.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.1.2)\n",
      "Requirement already satisfied: progress>=1.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.6)\n",
      "Requirement already satisfied: nibabel>=3.2.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (3.2.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.95 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.1.96)\n",
      "Requirement already satisfied: pandas~=1.1.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.1.5)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (6.0)\n",
      "Requirement already satisfied: scikit-image>=0.17.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.19.1)\n",
      "Requirement already satisfied: tokenizers>=0.10.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.11.2)\n",
      "Requirement already satisfied: nltk>=3.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (3.6.7)\n",
      "Requirement already satisfied: parasail>=1.2.4 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.2.4)\n",
      "Requirement already satisfied: jstyleson~=0.0.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (0.0.2)\n",
      "Requirement already satisfied: yamlloader>=0.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.1.0)\n",
      "Requirement already satisfied: networkx~=2.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (2.6.3)\n",
      "Requirement already satisfied: numpy<1.20,>=1.16.6 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.19.5)\n",
      "Requirement already satisfied: texttable~=1.6.3 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from openvino-dev) (1.6.4)\n",
      "Requirement already satisfied: future in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from hyperopt~=0.1.2->openvino-dev) (0.18.2)\n",
      "Requirement already satisfied: six in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from hyperopt~=0.1.2->openvino-dev) (1.16.0)\n",
      "Requirement already satisfied: pymongo in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from hyperopt~=0.1.2->openvino-dev) (4.0.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from nibabel>=3.2.1->openvino-dev) (21.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from nltk>=3.5->openvino-dev) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from nltk>=3.5->openvino-dev) (1.1.0)\n",
      "Requirement already satisfied: click in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from nltk>=3.5->openvino-dev) (8.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from packaging>=14.3->nibabel>=3.2.1->openvino-dev) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from pandas~=1.1.5->openvino-dev) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from pandas~=1.1.5->openvino-dev) (2021.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from requests>=2.25.1->openvino-dev) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from requests>=2.25.1->openvino-dev) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from requests>=2.25.1->openvino-dev) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from requests>=2.25.1->openvino-dev) (1.26.7)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from scikit-image>=0.17.2->openvino-dev) (2021.11.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from scikit-image>=0.17.2->openvino-dev) (2.13.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from scikit-image>=0.17.2->openvino-dev) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from scikit-learn>=0.24.1->openvino-dev) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from click->nltk>=3.5->openvino-dev) (4.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.5->openvino-dev) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages (from importlib-metadata->click->nltk>=3.5->openvino-dev) (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openvino-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a524c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/hbtian/MQBench0130/haibin_test/mqbench_qmodel_deploy_model.onnx\n",
      "\t- Path for generated IR: \t/home/hbtian/MQBench0130/haibin_test/.\n",
      "\t- IR output name: \tmqbench_qmodel_deploy_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "ONNX specific parameters:\n",
      "\t- Inference Engine found in: \t/home/hbtian/miniconda3/envs/mqbench/lib/python3.7/site-packages/openvino\n",
      "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
      "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
      "[ SUCCESS ] Generated IR version 10 model.\n",
      "[ SUCCESS ] XML file: /home/hbtian/MQBench0130/haibin_test/mqbench_qmodel_deploy_model.xml\n",
      "[ SUCCESS ] BIN file: /home/hbtian/MQBench0130/haibin_test/mqbench_qmodel_deploy_model.bin\n",
      "[ SUCCESS ] Total execution time: 3.03 seconds. \n",
      "[ SUCCESS ] Memory consumed: 74 MB. \n"
     ]
    }
   ],
   "source": [
    "!mo --input_model mqbench_qmodel_deploy_model.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8555b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22554fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(format=\"[ %(levelname)s ] %(message)s\", level=log.ERROR, stream=sys.stdout)\n",
    "log.info(\"Creating Inference Engine...\")\n",
    "ie = IECore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2396b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read IR\n",
    "log.info(\"Loading network\")\n",
    "net = ie.read_network(\"./mqbench_qmodel_deploy_model.xml\")\n",
    "\n",
    "img_info_input_blob = None\n",
    "feed_dict = {}\n",
    "input_blob = \"input\"\n",
    "for blob_name in net.input_info:\n",
    "    if len(net.input_info[blob_name].input_data.shape) == 4:\n",
    "        input_blob = blob_name\n",
    "    elif len(net.input_info[blob_name].input_data.shape) == 2:\n",
    "        img_info_input_blob = blob_name\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported {}D input layer '{}'. Only 2D and 4D input layers are supported\"\n",
    "                           .format(len(net.input_info[blob_name].input_data.shape), blob_name))\n",
    "\n",
    "log.info(\"Loading IR to the plugin...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "708dbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_net = ie.load_network(network=net, num_requests=4, device_name=\"CPU\")\n",
    "n, c, h, w = net.input_info[input_blob].input_data.shape\n",
    "if img_info_input_blob:\n",
    "    feed_dict[img_info_input_blob] = [h, w, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8931d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, c, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78345084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_openvino(exec_net, test_loader):\n",
    "    \n",
    "    global feed_dict\n",
    "    global input_blob\n",
    "    cur_request_id = 0\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    def infer(img):\n",
    "        cur_request_id = 0\n",
    "        feed_dict[input_blob] = img\n",
    "        exec_net.start_async(request_id=cur_request_id, inputs=feed_dict)\n",
    "        while exec_net.requests[cur_request_id].wait(-1) != 0:\n",
    "            pass\n",
    "        outs = exec_net.requests[cur_request_id].output_blobs\n",
    "        k = tuple(outs.keys())[0]\n",
    "        return outs[k].buffer\n",
    "    \n",
    "    lossLayer = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        for subdata, sub_target in zip(data, target):\n",
    "            output = infer(subdata.unsqueeze(dim=0).numpy())\n",
    "            output = torch.as_tensor(output)\n",
    "            test_loss += lossLayer(output, sub_target.unsqueeze(dim=0)).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(sub_target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(\n",
    "        test_loss, 100. * correct / len(test_loader.dataset)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b28fa145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6873, Accuracy: 77%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_openvino(exec_net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07c829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535a620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
